# -*- coding: utf-8 -*-
# MorphX - Toolkit for morphology exploration and segmentation
#
# Copyright (c) 2019 - now
# Max Planck Institute of Neurobiology, Martinsried, Germany
# Authors: Jonathan Klimesch, Philipp Schubert

import numpy as np
from typing import Tuple
from collections import deque
from morphx.classes.hybridcloud import HybridCloud
from morphx.classes.hybridmesh import HybridMesh
from morphx.classes.pointcloud import PointCloud
from morphx.classes.meshcloud import MeshCloud


# -------------------------------------- HYBRID EXTRACTION --------------------------------------- #

def extract_subset(hybrid: HybridCloud, local_bfs: np.ndarray) -> Tuple[PointCloud, np.ndarray]:
    """ Returns the mesh subset of given skeleton nodes based on a mapping dict
     between skeleton and mesh.

    Args:
        hybrid: MorphX HybridCloud object from which the subset should be extracted.
        local_bfs: Skeleton node index array which was generated by a local BFS.

    Returns:
        Mesh subset as PointCloud object
    """
    idcs = []
    for i in local_bfs:
        idcs.extend(hybrid.verts2node[i])
    verts = hybrid.vertices[idcs]
    feats, labels = None, None
    if hybrid.features is not None and len(hybrid.features) > 0:
        feats = hybrid.features[idcs]
    if hybrid.labels is not None and len(hybrid.labels) > 0:
        labels = hybrid.labels[idcs]
    return PointCloud(verts, labels=labels, features=feats, no_pred=hybrid.no_pred,
                      obj_bounds=hybrid.obj_bounds, encoding=hybrid.encoding), np.array(idcs)


def extract_mesh_subset(hm: HybridMesh, local_bfs: np.ndarray) -> MeshCloud:
    """ Returns the mesh subset of given skeleton nodes based on the face
     mapping dict between skeleton and mesh.

    Args:
        hm: HybridMesh from which the subset should be extracted.
        local_bfs: Skeleton node index array which was generated by a local BFS.

    Returns:
        Mesh subset as PointCloud object
    """
    mapping_face = hm.faces2node

    total_face = set()
    for node_ix in local_bfs:
        total_face.update(set(mapping_face[node_ix]))

    total_face = np.array(list(total_face), dtype=np.int)

    if len(total_face) == len(hm.faces):
        # all faces haven been selected
        new_faces = hm.faces
        new_vertices = hm.vertices
        new_labels = hm.labels
        new_normals = hm.normals
    else:
        new_faces = hm.faces[total_face]
        total_vertex = np.unique(new_faces.flatten()).astype(int)  # also sorts the ids
        new_vertices = hm.vertices[total_vertex]
        if len(hm.labels) > 0:
            new_labels = hm.labels[total_vertex]
        else:
            new_labels = None
        if len(hm.normals) > 0:
            new_normals = hm.normals[total_vertex]
        else:
            new_normals = None
        # normalize new faces to be contiguous
        face_shape = new_faces.shape
        new_faces = new_faces.flatten()
        updated_face_ixs = {face_id: k for k, face_id in enumerate(np.unique(new_faces))}
        for ix, old_face_ix in enumerate(new_faces):
            # update face indices
            new_faces[ix] = updated_face_ixs[old_face_ix]
        # switch to original shape
        new_faces = new_faces.reshape(face_shape)
    mc = MeshCloud(new_vertices, new_faces, new_normals, labels=new_labels,
                   encoding=hm.encoding)
    return mc


def label_search(hc: HybridCloud, source: int) -> int:
    if hc.node_labels is None:
        return source
    g = hc.graph()
    visited = [source]
    neighbors = g.neighbors(source)
    de = deque([i for i in neighbors])
    while de:
        curr = de.pop()
        if hc.node_labels[curr] != -1:
            return curr
        if curr not in visited:
            visited.append(curr)
            neighbors = g.neighbors(curr)
            de.extendleft([i for i in neighbors if i not in visited])
    return source
