# -*- coding: utf-8 -*-
# MorphX - Toolkit for morphology exploration and segmentation
#
# Copyright (c) 2019 - now
# Max Planck Institute of Neurobiology, Martinsried, Germany
# Authors: Jonathan Klimesch, Philipp Schubert

import time
import ipdb
import numpy as np
from typing import Tuple
from collections import deque
from morphx.classes.hybridcloud import HybridCloud
from morphx.classes.hybridmesh import HybridMesh
from morphx.classes.pointcloud import PointCloud


# -------------------------------------- HYBRID EXTRACTION --------------------------------------- #

def extract_subset(hybrid: HybridCloud, local_bfs: np.ndarray) -> Tuple[PointCloud, np.ndarray]:
    """ Returns the mesh subset of given skeleton nodes based on a mapping dict
     between skeleton and mesh.

    Args:
        hybrid: MorphX HybridCloud object from which the subset should be extracted.
        local_bfs: Skeleton node index array which was generated by a local BFS.

    Returns:
        Mesh subset as PointCloud object
    """
    idcs = []
    for i in local_bfs:
        idcs.extend(hybrid.verts2node[i])
    verts = hybrid.vertices[idcs]
    feats, labels = None, None
    if hybrid.features is not None and len(hybrid.features) > 0:
        feats = hybrid.features[idcs]
    if hybrid.labels is not None and len(hybrid.labels) > 0:
        labels = hybrid.labels[idcs]
    return PointCloud(verts, labels=labels, features=feats, no_pred=hybrid.no_pred,
                      obj_bounds=hybrid.obj_bounds, encoding=hybrid.encoding), np.array(idcs)


def extract_mesh_subset(hm: HybridMesh, local_bfs: np.ndarray) -> HybridMesh:
    """ Returns the mesh subset of given skeleton nodes based on the face
     mapping dict between skeleton and mesh.

    Args:
        hm: HybridMesh from which the subset should be extracted.
        local_bfs: Skeleton node index array which was generated by a local BFS.

    Returns:
        Mesh subset as PointCloud object
    """
    mapping_face = hm.faces2node

    total_face = set()
    for node_ix in local_bfs:
        total_face.update(set(mapping_face[node_ix]))

    total_face = np.array(list(total_face), dtype=np.int)

    if len(total_face) == len(hm.faces):
        # all faces haven been selected
        new_faces = hm.faces
        new_vertices = hm.vertices
        new_labels = hm.labels
        new_normals = hm.normals
        new_features = hm.features
    else:
        new_faces = hm.faces[total_face]
        total_vertex = np.unique(new_faces.flatten()).astype(int)  # also sorts the ids
        new_vertices = hm.vertices[total_vertex]
        if len(hm.labels) > 0:
            new_labels = hm.labels[total_vertex]
        else:
            new_labels = None
        if len(hm.normals) > 0:
            new_normals = hm.normals[total_vertex]
        else:
            new_normals = None
        if len(hm.features) > 0:
            new_features = hm.features[total_vertex]
        else:
            new_features = None
        # normalize new faces to be contiguous
        face_shape = new_faces.shape
        new_faces = new_faces.flatten()
        updated_face_ixs = {face_id: k for k, face_id in enumerate(np.unique(new_faces))}
        for ix, old_face_ix in enumerate(new_faces):
            # update face indices
            new_faces[ix] = updated_face_ixs[old_face_ix]
        # switch to original shape
        new_faces = new_faces.reshape(face_shape)
    hm = HybridMesh(vertices=new_vertices, faces=new_faces, normals=new_normals, labels=new_labels,
                    features=new_features, encoding=hm.encoding)
    return hm


# -------------------------------------- HYBRID GRAPH ALGORITHMS --------------------------------------- #

def label_search(hc: HybridCloud, source: int) -> int:
    """ Performs BFS on nodes starting from source until first node with label != -1 has been found.

    Args:
        hc: HybridCloud in which source is part of the graph
        source: The node for which the first neighboring node with label != -1 should be found.

    Returns:
        The index of the first node with label != -1
    """
    if hc.node_labels is None:
        return source
    g = hc.graph()
    visited = [source]
    neighbors = g.neighbors(source)
    de = deque([i for i in neighbors])
    while de:
        curr = de.pop()
        if hc.node_labels[curr] != -1:
            return curr
        if curr not in visited:
            visited.append(curr)
            neighbors = g.neighbors(curr)
            de.extendleft([i for i in neighbors if i not in visited])
    return source


def bfs_vertices(hc: HybridCloud, source: int, vertex_max: int) -> np.ndarray:
    """ Performs a BFS on a graph until the number of vertices which correspond to
        the currently selected nodes reaches the maximum.

    Args:
        hc: The HybridCloud with the graph, nodes and vertices on which the BFS should be performed
        source: The source node from which the BFS should start.
        vertex_max: The maximum number of vertices after which the BFS should stop.

    Returns:
        np.ndarray with nodes sorted recording to the result of the limited BFS
    """
    visited = [source]
    vertex_num = len(hc.verts2node[source])
    neighbors = hc.graph().neighbors(source)
    de = deque([i for i in neighbors])
    while de:
        curr = de.pop()
        if curr not in visited:
            if vertex_num + len(hc.verts2node[curr]) <= vertex_max:
                visited.append(curr)
                vertex_num += len(hc.verts2node[curr])
                neighbors = hc.graph().neighbors(curr)
                de.extendleft([i for i in neighbors if i not in visited])
            else:
                return np.array(visited)

    return np.array(visited)


def bfs_vertices_euclid(hc: HybridCloud, source: int, vertex_max: int, euclid: int, cutoff: int = 20) -> np.ndarray:
    """ Starting from the source, a bfs is performed until 'context' consecutive nodes have a distance > 'euclid'
        from the source. The resulting node list is then iterated until the maximum number of vertices is reached.
        This gets all nodes within a certain radius in the order they would appear when traversing the skeleton.

    Args:
        hc: The HybridCloud with the graph, nodes and vertices on which the BFS should be performed
        source: The source node from which the BFS should start.
        vertex_max: The maximum number of vertices which should be included in the chunk
        euclid: All nodes within this radius of the source are iterated
        cutoff: BFS gets performed until 'context' consecutive nodes have a distance > 'euclid' from
            the source

    Returns:
        np.ndarray with nodes which were extracted during the bfs
    """
    g = hc.graph()
    source_pos = g.nodes[source]['position']
    # run bfs in order to get node context on which following k-nearest neighbor search is faster
    visited = [source]
    node_extract = [source]
    neighbors = g.neighbors(source)
    de = deque([(i, [i]) for i in neighbors])
    while de:
        curr, out_preds = de.pop()
        if curr not in visited:
            visited.append(curr)
            if np.linalg.norm(source_pos - g.nodes[curr]['position']) <= euclid:
                node_extract.append(curr)
                out_preds = []
            # don't add neighbors if previous 'context' nodes are outside of euclidian sphere
            if len(out_preds) < cutoff:
                neighbors = g.neighbors(curr)
                for i in neighbors:
                    if i not in visited:
                        new_out_preds = out_preds.copy()
                        new_out_preds.append(i)
                        de.extendleft([(i, new_out_preds)])
    bfs_result = []
    vertex_num = 0
    ix = 0
    while vertex_num <= vertex_max and ix < len(node_extract):
        vertex_num += len(hc.verts2node[node_extract[ix]])
        bfs_result.append(node_extract[ix])
        ix += 1
    return np.array(bfs_result)


def bfs_vertices_diameter(hc: HybridCloud, source: int, vertex_max: int, radius: int = 500) -> np.ndarray:
    """ Adds nodes to result as long as number of corresponding vertices is below a given threshold. To be
        independent from the skeleton structure, for each node all nodes within a certain radius get
        considered. """
    source = int(source)
    chosen = []
    idx_nodes = np.arange(len(hc.nodes))
    visited = [source]
    dia_nodes = idx_nodes[np.linalg.norm(hc.nodes - hc.nodes[source], axis=1) <= radius]
    vertex_num = 0
    # add nodes as long as number of corresponding vertices is still below the threshold
    for node in dia_nodes:
        if vertex_num + len(hc.verts2node[node]) <= vertex_max:
            chosen.append(node)
            vertex_num += len(hc.verts2node[node])
        else:
            return np.array(chosen)
    neighbors = hc.graph().neighbors(source)
    de = deque([i for i in neighbors])
    while de:
        curr = de.pop()
        if curr not in visited:
            visited.append(curr)
            dia_nodes = idx_nodes[np.linalg.norm(hc.nodes - hc.nodes[curr], axis=1) <= radius]
            for node in dia_nodes:
                if node not in chosen:
                    if vertex_num + len(hc.verts2node[node]) <= vertex_max:
                        chosen.append(node)
                        vertex_num += len(hc.verts2node[node])
                    else:
                        return np.array(chosen)
            neighbors = hc.graph().neighbors(curr)
            de.extendleft([i for i in neighbors if i not in visited])
    return np.array(chosen)


def bfs_base_points_density(hc: HybridCloud, vertex_max: int, source: int = -1) -> np.ndarray:
    """ Extracts base points which have an approximate number of vertices between them.

    Args:
        hc: the HybridCloud with the graph and vertices.
        vertex_max: the approximate number of vertices which should be between two base points
            (corresponding to the nodes between them)
        source: the starting point.
    """
    # after context nodes the number of vertices between the current and the starting node is checked
    # if vertex number is higher than threshold the node gets added as a base point (doing this context-
    # wise speeds up the process in contrast to doing it node-wise)
    counter = 0
    context = 20
    if source == -1:
        source = np.random.randint(hc.graph().number_of_nodes())
    chosen = [source]
    visited = [source]
    neighbors = hc.graph().neighbors(source)
    de = deque([(i, [source], 0) for i in neighbors])
    while de:
        counter += 1
        print(counter)
        curr, preds, verts_num = de.pop()
        if curr not in visited:
            visited.append(curr)
            # sum up all corresponding vertices after each 'context' nodes
            if len(preds) >= context:
                for node in preds:
                    verts_num += len(hc.verts2node[node])
                if verts_num > vertex_max:
                    # include this node only if there are enough vertices between this one and all nodes
                    # which were already chosen
                    include = True
                    for chosen_node in reversed(chosen):
                        if np.linalg.norm(hc.nodes[curr] - hc.nodes[chosen_node]) < 5000:
                            include = False
                        # if not enough_vertices(hc, vertex_max, curr, chosen_node):
                        #     include = False
                        #     break
                    if include:
                        chosen.append(curr)
                        verts_num = 0
                # reset the context to process the next 'context' nodes. The number of vertices
                # is still the old one unless the node was added as a base point
                preds = []
            preds.append(curr)
            neighbors = hc.graph().neighbors(curr)
            de.extendleft([(i, preds, verts_num) for i in neighbors])
    return np.array(chosen)


def enough_vertices(hc: HybridCloud, vertex_max: int, source: int, goal: int) -> bool:
    """ Checks if number of vertices corresponding to the skeleton nodes between the source and the
        nearest node in chosen is below a certain threshold. Can be used to ensure a minimum distance
        between base points.

    Args:
        hc: the HybridCloud with the graph and vertices
        vertex_max: the threshold from the description
        source: the starting point
        goal: a list of nodes from which the nearest node to the source is decisive

    Returns:
        True if there are enough vertices between the source and the next node in chosen, False
        otherwise
    """
    visited = [source]
    vertex_num = len(hc.verts2node[source])
    neighbors = hc.graph().neighbors(source)
    de = deque([(i, vertex_num) for i in neighbors])
    while de:
        curr, vertex_num = de.pop()
        if curr not in visited:
            visited.append(curr)
            vertex_num += len(hc.verts2node[curr])
            # if goal node was reached, but not enough vertices are in between, return False
            if curr == goal and vertex_num < vertex_max:
                return False
            # if there are enough vertices and goal has not been or has just been reached, return True
            if vertex_num > vertex_max:
                return True
            neighbors = hc.graph().neighbors(curr)
            de.extendleft([(i, vertex_num) for i in neighbors])
    return True
