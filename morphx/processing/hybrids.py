# -*- coding: utf-8 -*-
# MorphX - Toolkit for morphology exploration and segmentation
#
# Copyright (c) 2019 - now
# Max Planck Institute of Neurobiology, Martinsried, Germany
# Authors: Jonathan Klimesch, Philipp Schubert

import numpy as np
from typing import Tuple
from collections import deque
from scipy.spatial.ckdtree import cKDTree
from morphx.classes.hybridcloud import HybridCloud
from morphx.classes.hybridmesh import HybridMesh
from morphx.classes.pointcloud import PointCloud


# -------------------------------------- HYBRID EXTRACTION --------------------------------------- #

def extract_subset(hybrid: HybridCloud, local_bfs: np.ndarray) -> Tuple[PointCloud, np.ndarray]:
    """ Returns the mesh subset of given skeleton nodes based on a mapping dict
     between skeleton and mesh.

    Args:
        hybrid: MorphX HybridCloud object from which the subset should be extracted.
        local_bfs: Skeleton node index array which was generated by a local BFS.

    Returns:
        Mesh subset as PointCloud object
    """
    idcs = []
    for i in local_bfs:
        idcs.extend(hybrid.verts2node[i])
    verts = hybrid.vertices[idcs]
    feats, labels = None, None
    if hybrid.features is not None and len(hybrid.features) > 0:
        feats = hybrid.features[idcs]
    if hybrid.labels is not None and len(hybrid.labels) > 0:
        labels = hybrid.labels[idcs]
    return PointCloud(verts, labels=labels, features=feats, no_pred=hybrid.no_pred,
                      obj_bounds=hybrid.obj_bounds, encoding=hybrid.encoding), np.array(idcs)


def extract_mesh_subset(hm: HybridMesh, local_bfs: np.ndarray) -> HybridMesh:
    """ Returns the mesh subset of given skeleton nodes based on the face
     mapping dict between skeleton and mesh.

    Args:
        hm: HybridMesh from which the subset should be extracted.
        local_bfs: Skeleton node index array which was generated by a local BFS.

    Returns:
        Mesh subset as PointCloud object
    """
    mapping_face = hm.faces2node

    total_face = set()
    for node_ix in local_bfs:
        total_face.update(set(mapping_face[node_ix]))

    total_face = np.array(list(total_face), dtype=np.int)

    if len(total_face) == len(hm.faces):
        # all faces haven been selected
        new_faces = hm.faces
        new_vertices = hm.vertices
        new_labels = hm.labels
        new_normals = hm.normals
        new_features = hm.features
    else:
        new_faces = hm.faces[total_face]
        total_vertex = np.unique(new_faces.flatten()).astype(int)  # also sorts the ids
        new_vertices = hm.vertices[total_vertex]
        if len(hm.labels) > 0:
            new_labels = hm.labels[total_vertex]
        else:
            new_labels = None
        if len(hm.normals) > 0:
            new_normals = hm.normals[total_vertex]
        else:
            new_normals = None
        if len(hm.features) > 0:
            new_features = hm.features[total_vertex]
        else:
            new_features = None
        # normalize new faces to be contiguous
        face_shape = new_faces.shape
        new_faces = new_faces.flatten()
        updated_face_ixs = {face_id: k for k, face_id in enumerate(np.unique(new_faces))}
        for ix, old_face_ix in enumerate(new_faces):
            # update face indices
            new_faces[ix] = updated_face_ixs[old_face_ix]
        # switch to original shape
        new_faces = new_faces.reshape(face_shape)
    hm = HybridMesh(vertices=new_vertices, faces=new_faces, normals=new_normals, labels=new_labels,
                    features=new_features, encoding=hm.encoding)
    return hm


# -------------------------------------- HYBRID GRAPH ALGORITHMS --------------------------------------- #

def label_search(hc: HybridCloud, source: int) -> int:
    """ Performs BFS on nodes starting from source until first node with label != -1 has been found.

    Args:
        hc: HybridCloud in which source is part of the graph
        source: The node for which the first neighboring node with label != -1 should be found.

    Returns:
        The index of the first node with label != -1
    """
    if hc.node_labels is None:
        return source
    g = hc.graph()
    visited = [source]
    neighbors = g.neighbors(source)
    de = deque([i for i in neighbors])
    while de:
        curr = de.pop()
        if hc.node_labels[curr] != -1:
            return curr
        if curr not in visited:
            visited.append(curr)
            neighbors = g.neighbors(curr)
            de.extendleft([i for i in neighbors if i not in visited])
    return source


def bfs_vertices(hc: HybridCloud, source: int, vertex_max: int) -> np.ndarray:
    """ Performs a BFS on a graph until the number of vertices which correspond to
        the currently selected nodes reaches the maximum.

    Args:
        hc: The HybridCloud with the graph, nodes and vertices on which the BFS should be performed
        source: The source node from which the BFS should start.
        vertex_max: The maximum number of vertices after which the BFS should stop.

    Returns:
        np.ndarray with nodes sorted recording to the result of the limited BFS
    """
    visited = [source]
    vertex_num = len(hc.verts2node[source])
    neighbors = hc.graph().neighbors(source)
    de = deque([i for i in neighbors])
    while de:
        curr = de.pop()
        if curr not in visited:
            if vertex_num + len(hc.verts2node[curr]) <= vertex_max:
                visited.append(curr)
                vertex_num += len(hc.verts2node[curr])
                neighbors = hc.graph().neighbors(curr)
                de.extendleft([i for i in neighbors if i not in visited])
            else:
                return np.array(visited)

    return np.array(visited)


def bfs_vertices_euclid(hc: HybridCloud, source: int, vertex_max: int, euclid: int, context: int = 20) -> np.ndarray:
    """ 1. Reduce number of nodes of interest by exploiting the skeleton structure and extracting nodes
        within a certain euclidian radius
        2. Get independent from the (possibly irregular) skeleton by performing a k-nearest neighbor search
        on the node extract with respect to the source
        3. Iterate the k-nearest neighbors in ascending order until maximum number of corresponding vertices
        is reached

    Args:
        hc: The HybridCloud with the graph, nodes and vertices on which the BFS should be performed
        source: The source node from which the BFS should start.
        vertex_max: The maximum number of vertices which should be included in the chunk
        euclid: All nodes within this radius of the source are iterated
        context: Used for creating the node context which speeds up the k-nearest neighbor search. Starting
            from the source, a bfs is performed until 'context' consecutive nodes are outside of the 'euclid'
            radius

    Returns:
        np.ndarray with nodes which were extracted during this bfs
    """
    g = hc.graph()
    source_pos = g.nodes[source]['position']
    # run bfs in order to get node context on which following k-nearest neighbor search is faster
    visited = [source]
    node_extract = []
    neighbors = g.neighbors(source)
    de = deque([(i, [i]) for i in neighbors])
    while de:
        curr, out_preds = de.pop()
        if curr not in visited:
            visited.append(curr)
            if np.linalg.norm(source_pos - g.nodes[curr]['position']) <= euclid:
                node_extract.append(curr)
                out_preds = []
            # don't add neighbors if previous 'context' nodes are outside of euclidian sphere
            if len(out_preds) < context:
                neighbors = g.neighbors(curr)
                for i in neighbors:
                    if i not in visited:
                        new_out_preds = out_preds.copy()
                        new_out_preds.append(i)
                        de.extendleft([(i, new_out_preds)])

    # the node context contains all nodes within a certain euclidian radius. In order to get independent from the
    # skeleton, the graph structure gets abandoned and the nodes are iterated in order of their distance to the source.
    # This is computationally feasible as the extracted node context only contains a few (probably < 100) nodes.
    extract_coords = np.zeros((len(node_extract), 3))
    for ix, node in enumerate(node_extract):
        extract_coords[ix] = g.nodes[node]['position']
    tree = cKDTree(extract_coords)
    dist, ind = tree.query(source_pos, k=len(extract_coords))
    if isinstance(ind, int):
        ind = np.array([ind])

    # iterate query result in order of distance (small to large) and add nodes to result as long as the number of
    # corresponding vertices is below the specified number
    vertex_num = len(hc.verts2node[source])
    bfs_result = [source]
    for ix in ind:
        node = node_extract[ix]
        if vertex_num + len(hc.verts2node[node]) <= vertex_max:
            bfs_result.append(node)
            vertex_num += len(hc.verts2node[node])
        else:
            break

    return np.array(bfs_result)
