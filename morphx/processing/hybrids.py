# -*- coding: utf-8 -*-
# MorphX - Toolkit for morphology exploration and segmentation
#
# Copyright (c) 2019 - now
# Max Planck Institute of Neurobiology, Martinsried, Germany
# Authors: Jonathan Klimesch, Philipp Schubert

import numpy as np
from typing import Tuple
from collections import deque
from scipy.spatial import cKDTree
from morphx.classes.hybridcloud import HybridCloud
from morphx.classes.hybridmesh import HybridMesh
from morphx.classes.pointcloud import PointCloud


# -------------------------------------- HYBRID EXTRACTION --------------------------------------- #

def extract_subset(hybrid: HybridCloud, local_bfs: np.ndarray) -> Tuple[PointCloud, np.ndarray]:
    """ Returns the mesh subset of given skeleton nodes based on a mapping dict
     between skeleton and mesh.

    Args:
        hybrid: MorphX HybridCloud object from which the subset should be extracted.
        local_bfs: Skeleton node index array which was generated by a local BFS.

    Returns:
        Mesh subset as PointCloud object
    """
    idcs = []
    for i in local_bfs:
        idcs.extend(hybrid.verts2node[i])
    verts = hybrid.vertices[idcs]
    feats, labels = None, None
    if hybrid.features is not None and len(hybrid.features) > 0:
        feats = hybrid.features[idcs]
    if hybrid.labels is not None and len(hybrid.labels) > 0:
        labels = hybrid.labels[idcs]
    return PointCloud(verts, labels=labels, features=feats, no_pred=hybrid.no_pred,
                      obj_bounds=hybrid.obj_bounds, encoding=hybrid.encoding), np.array(idcs)


def extract_mesh_subset(hm: HybridMesh, local_bfs: np.ndarray) -> HybridMesh:
    """ Returns the mesh subset of given skeleton nodes based on the face
     mapping dict between skeleton and mesh.

    Args:
        hm: HybridMesh from which the subset should be extracted.
        local_bfs: Skeleton node index array which was generated by a local BFS.

    Returns:
        Mesh subset as PointCloud object
    """
    mapping_face = hm.faces2node

    total_face = set()
    for node_ix in local_bfs:
        total_face.update(set(mapping_face[node_ix]))

    total_face = np.array(list(total_face), dtype=np.int)

    if len(total_face) == len(hm.faces):
        # all faces haven been selected
        new_faces = hm.faces
        new_vertices = hm.vertices
        new_labels = hm.labels
        new_normals = hm.normals
        new_features = hm.features
    else:
        new_faces = hm.faces[total_face]
        total_vertex = np.unique(new_faces.flatten()).astype(int)  # also sorts the ids
        new_vertices = hm.vertices[total_vertex]
        if len(hm.labels) > 0:
            new_labels = hm.labels[total_vertex]
        else:
            new_labels = None
        if len(hm.normals) > 0:
            new_normals = hm.normals[total_vertex]
        else:
            new_normals = None
        if len(hm.features) > 0:
            new_features = hm.features[total_vertex]
        else:
            new_features = None
        # normalize new faces to be contiguous
        face_shape = new_faces.shape
        new_faces = new_faces.flatten()
        updated_face_ixs = {face_id: k for k, face_id in enumerate(np.unique(new_faces))}
        for ix, old_face_ix in enumerate(new_faces):
            # update face indices
            new_faces[ix] = updated_face_ixs[old_face_ix]
        # switch to original shape
        new_faces = new_faces.reshape(face_shape)
    hm = HybridMesh(vertices=new_vertices, faces=new_faces, normals=new_normals, labels=new_labels,
                    features=new_features, encoding=hm.encoding)
    return hm


# -------------------------------------- HYBRID GRAPH ALGORITHMS --------------------------------------- #

def label_search(hc: HybridCloud, source: int) -> int:
    """ Performs BFS on nodes starting from source until first node with label != -1 has been found.

    Args:
        hc: HybridCloud in which source is part of the graph
        source: The node for which the first neighboring node with label != -1 should be found.

    Returns:
        The index of the first node with label != -1
    """
    if hc.node_labels is None:
        return source
    g = hc.graph()
    visited = [source]
    neighbors = g.neighbors(source)
    de = deque([i for i in neighbors])
    while de:
        curr = de.pop()
        if hc.node_labels[curr] != -1:
            return curr
        if curr not in visited:
            visited.append(curr)
            neighbors = g.neighbors(curr)
            de.extendleft([i for i in neighbors if i not in visited])
    return source


def bfs_vertices(hc: HybridCloud, source: int, vertex_max: int) -> np.ndarray:
    """ Performs a BFS on a graph until the number of vertices which correspond to
        the currently selected nodes reaches the maximum.

    Args:
        hc: The HybridCloud with the graph, nodes and vertices on which the BFS should be performed
        source: The source node from which the BFS should start.
        vertex_max: The maximum number of vertices after which the BFS should stop.

    Returns:
        np.ndarray with nodes sorted recording to the result of the limited BFS
    """
    visited = [source]
    vertex_num = len(hc.verts2node[source])
    neighbors = hc.graph().neighbors(source)
    de = deque([i for i in neighbors])
    while de:
        curr = de.pop()
        if curr not in visited:
            if vertex_num + len(hc.verts2node[curr]) <= vertex_max:
                visited.append(curr)
                vertex_num += len(hc.verts2node[curr])
                neighbors = hc.graph().neighbors(curr)
                de.extendleft([i for i in neighbors if i not in visited])
            else:
                return np.array(visited)

    return np.array(visited)


def bfs_vertices_euclid(hc: HybridCloud, source: int, vertex_max: int, euclid: int, cutoff: int = 20) -> np.ndarray:
    """ Starting from the source, a bfs is performed until 'context' consecutive nodes have a distance > 'euclid'
        from the source. The resulting node list is then iterated until the maximum number of vertices is reached.
        This gets all nodes within a certain radius in the order they would appear when traversing the skeleton.

    Args:
        hc: The HybridCloud with the graph, nodes and vertices on which the BFS should be performed
        source: The source node from which the BFS should start.
        vertex_max: The maximum number of vertices which should be included in the chunk
        euclid: All nodes within this radius of the source are iterated
        cutoff: BFS gets performed until 'context' consecutive nodes have a distance > 'euclid' from
            the source

    Returns:
        np.ndarray with nodes which were extracted during the bfs
    """
    g = hc.graph()
    source_pos = g.nodes[source]['position']
    # run bfs in order to get node context on which following k-nearest neighbor search is faster
    visited = [source]
    node_extract = [source]
    neighbors = g.neighbors(source)
    de = deque([(i, [i]) for i in neighbors])
    while de:
        curr, out_preds = de.pop()
        if curr not in visited:
            visited.append(curr)
            if np.linalg.norm(source_pos - g.nodes[curr]['position']) <= euclid:
                node_extract.append(curr)
                out_preds = []
            # don't add neighbors if previous 'context' nodes are outside of euclidian sphere
            if len(out_preds) < cutoff:
                neighbors = g.neighbors(curr)
                for i in neighbors:
                    if i not in visited:
                        new_out_preds = out_preds.copy()
                        new_out_preds.append(i)
                        de.extendleft([(i, new_out_preds)])
    bfs_result = []
    vertex_num = 0
    ix = 0
    while vertex_num <= vertex_max and ix < len(node_extract):
        vertex_num += len(hc.verts2node[node_extract[ix]])
        bfs_result.append(node_extract[ix])
        ix += 1
    return np.array(bfs_result)


def bfs_vertices_diameter(hc: HybridCloud, source: int, vertex_max: int, radius: int = 1200) -> np.ndarray:
    """ Adds nodes to result as long as number of corresponding vertices is below a given threshold. To be
        independent from the skeleton structure, for each node all nodes within a certain radius get
        considered. """
    source = int(source)
    chosen = []
    idx_nodes = np.arange(len(hc.nodes))
    visited = [source]
    dia_nodes = idx_nodes[np.linalg.norm(hc.nodes - hc.nodes[source], axis=1) <= radius]
    vertex_num = 0
    # add nodes as long as number of corresponding vertices is still below the threshold
    for node in dia_nodes:
        if vertex_num + len(hc.verts2node[node]) <= vertex_max:
            chosen.append(node)
            vertex_num += len(hc.verts2node[node])
        else:
            return np.array(chosen)
    neighbors = hc.graph().neighbors(source)
    de = deque([i for i in neighbors])
    while de:
        curr = de.pop()
        if curr not in visited:
            visited.append(curr)
            dia_nodes = idx_nodes[np.linalg.norm(hc.nodes - hc.nodes[curr], axis=1) <= radius]
            for node in dia_nodes:
                if node not in chosen:
                    if vertex_num + len(hc.verts2node[node]) <= vertex_max:
                        chosen.append(node)
                        vertex_num += len(hc.verts2node[node])
                    else:
                        return np.array(chosen)
            neighbors = hc.graph().neighbors(curr)
            de.extendleft([i for i in neighbors if i not in visited])
    return np.array(chosen)


def bfs_base_points_density(hc: HybridCloud, vertex_max: int, source: int = -1, radius: int = 1200) -> np.ndarray:
    """ Adds base points which have a certain number of vertices between them. """
    if source == -1:
        source = np.random.randint(g.number_of_nodes())
    visited = [source]
    closed = []
    chosen = [source]
    idx_nodes = np.arange(len(hc.nodes))
    dia_nodes = idx_nodes[np.linalg.norm(hc.nodes - hc.nodes[source], axis=1) <= radius]
    vertex_num = 0
    for node in dia_nodes:
        closed.append(node)
        vertex_num += len(hc.verts2node[node])
    neighbors = hc.graph().neighbors(source)
    de = deque([(i, vertex_num) for i in neighbors])
    while de:
        curr, vertex_num = de.pop()
        if curr not in visited:
            visited.append(curr)
            dia_nodes = idx_nodes[np.linalg.norm(hc.nodes - hc.nodes[curr], axis=1) <= radius]
            for node in dia_nodes:
                closed.append(node)
                vertex_num += len(hc.verts2node[node])
            # add to base points if vertex number since last base point exceeds threshold and if node is not too near
            # to other, already visited points
            if vertex_num > vertex_max and curr not in closed:
                chosen.append(curr)
                vertex_num = 0
            neighbors = hc.graph().neighbors(curr)
            de.extendleft([(i, vertex_num) for i in neighbors if i not in visited])
    return np.array(chosen)
